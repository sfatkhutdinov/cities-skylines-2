# Cities Skylines 2 Autonomous Agent

![Cities Skylines 2](https://image.api.playstation.com/vulcan/ap/rnd/202306/0816/3214e62bc2f655c5417a0a3dcaafdbc62d9447ebb58919b7.jpg)

## ðŸŒ† Overview

This project implements an autonomous reinforcement learning agent that learns to play Cities Skylines 2 through pure visual observation and keyboard/mouse inputs. The agent operates with no access to the game's internal state or API, using only what it can "see" on screen to make decisions.

## ðŸ§  Technical Architecture

The project uses a deep reinforcement learning approach with the following components:

### Core Components

- **Environment**: Captures game state through screen capture, processes observations, and manages interactions with the game.
  - `environment/core`: Core environment interfaces and infrastructure
  - `environment/input`: Keyboard and mouse input simulation
  - `environment/menu`: Menu detection and navigation
  - `environment/rewards`: Reward computation based on visual changes
  - `environment/mock_environment.py`: Simulated environment for testing without the game
  - `environment/optimized_capture.py`: Optimized screen capture implementation
  - `environment/visual_metrics.py`: Visual metrics and measurements

- **Agent**: Implements the PPO (Proximal Policy Optimization) reinforcement learning algorithm.
  - `agent/core`: Core agent components (policy, value, memory, updater)
  - `agent/memory_agent.py`: Memory-augmented agent implementation
  - `agent/hierarchical_agent.py`: Hierarchical agent architecture

- **Memory**: Implements memory-augmented architectures for enhanced agent capabilities.
  - `memory/memory_augmented_network.py`: Neural memory architecture
  - `memory/episodic_memory.py`: Episodic memory functionality

- **Model**: Neural network architecture for policy and value functions.
  - `model/optimized_network.py`: Optimized CNN network for visual processing
  - `model/visual_understanding_network.py`: Visual scene understanding
  - `model/world_model.py`: World modeling for predictions
  - `model/error_detection_network.py`: Error detection for the game

- **Training**: Manages the training process, checkpoints, and signal handling.
  - `training/trainer.py`: Training loop and management
  - `training/checkpointing.py`: Checkpoint saving and loading
  - `training/signal_handlers.py`: Handles interrupts and signals
  - `training/memory_trainer.py`: Trainer for memory-augmented agent
  - `training/hierarchical_trainer.py`: Trainer for hierarchical agent

- **Utils**: Utility functions and services including monitoring capabilities.
  - `utils/image_utils.py`: Image processing utilities
  - `utils/hardware_monitor.py`: System resource monitoring
  - `utils/performance_safeguards.py`: Ensures stable performance
  - `utils/visualization.py`: Visualization tools
  - `utils/path_utils.py`: Path management for consistent file locations

- **Config**: Configuration for hardware and action space.
  - `config/hardware_config.py`: Hardware configuration
  - `config/action_space.py`: Action space definition
  - `config/training_config.py`: Training parameters and settings
  - `config/config_loader.py`: Configuration loading utilities

- **Benchmarks**: Tools for performance analysis and optimization.
  - `benchmarks/benchmark_agent.py`: Measures agent performance metrics

- **Tests**: Automated testing infrastructure.
  - `tests/test_mock_environment.py`: Tests for the mock environment

### Project Structure

```
cities-skylines-2/
â”œâ”€â”€ src/                                # Source code directory
â”‚   â”œâ”€â”€ agent/                          # Agent modules
â”‚   â”‚   â”œâ”€â”€ core/                       # Core agent components
â”‚   â”‚   â”‚   â”œâ”€â”€ memory.py               # Memory buffer implementation
â”‚   â”‚   â”‚   â”œâ”€â”€ policy.py               # Policy network and action selection
â”‚   â”‚   â”‚   â”œâ”€â”€ ppo_agent.py            # PPO algorithm implementation
â”‚   â”‚   â”‚   â”œâ”€â”€ updater.py              # Network update logic
â”‚   â”‚   â”‚   â””â”€â”€ value.py                # Value function implementation
â”‚   â”‚   â”œâ”€â”€ hierarchical_agent.py       # Hierarchical agent architecture
â”‚   â”‚   â””â”€â”€ memory_agent.py             # Memory-augmented agent implementation
â”‚   â”‚
â”‚   â”œâ”€â”€ benchmarks/                     # Benchmarking tools
â”‚   â”‚   â””â”€â”€ benchmark_agent.py          # Agent performance evaluation
â”‚   â”‚
â”‚   â”œâ”€â”€ config/                         # Configuration
â”‚   â”‚   â”œâ”€â”€ defaults/                   # Default configuration files
â”‚   â”‚   â”œâ”€â”€ action_space.py             # Action space definition
â”‚   â”‚   â”œâ”€â”€ config_loader.py            # Configuration loading utilities
â”‚   â”‚   â”œâ”€â”€ example_config.json         # Example configuration file
â”‚   â”‚   â”œâ”€â”€ hardware_config.py          # Hardware-specific configuration
â”‚   â”‚   â””â”€â”€ training_config.py          # Training parameters and settings
â”‚   â”‚
â”‚   â”œâ”€â”€ environment/                    # Environment modules
â”‚   â”‚   â”œâ”€â”€ core/                       # Core environment components
â”‚   â”‚   â”œâ”€â”€ input/                      # Keyboard and mouse input simulation
â”‚   â”‚   â”œâ”€â”€ menu/                       # Menu detection and navigation
â”‚   â”‚   â”œâ”€â”€ rewards/                    # Reward computation
â”‚   â”‚   â”œâ”€â”€ mock_environment.py         # Simulated environment
â”‚   â”‚   â”œâ”€â”€ optimized_capture.py        # Screen capture optimization
â”‚   â”‚   â””â”€â”€ visual_metrics.py           # Visual-based metrics calculation
â”‚   â”‚
â”‚   â”œâ”€â”€ memory/                         # Memory-augmented architectures
â”‚   â”‚   â”œâ”€â”€ episodic_memory.py          # Episodic memory implementation
â”‚   â”‚   â””â”€â”€ memory_augmented_network.py # Neural network with memory capabilities
â”‚   â”‚
â”‚   â”œâ”€â”€ model/                          # Neural network models
â”‚   â”‚   â”œâ”€â”€ error_detection_network.py  # Error detection for the game
â”‚   â”‚   â”œâ”€â”€ optimized_network.py        # Optimized CNN architecture
â”‚   â”‚   â”œâ”€â”€ visual_understanding_network.py # Visual scene understanding
â”‚   â”‚   â””â”€â”€ world_model.py              # World modeling for predictions
â”‚   â”‚
â”‚   â”œâ”€â”€ training/                       # Training infrastructure
â”‚   â”‚   â”œâ”€â”€ checkpointing.py            # Model checkpoint management
â”‚   â”‚   â”œâ”€â”€ hierarchical_trainer.py     # Trainer for hierarchical agent
â”‚   â”‚   â”œâ”€â”€ memory_trainer.py           # Trainer for memory-augmented agent
â”‚   â”‚   â”œâ”€â”€ signal_handlers.py          # Handles system signals during training
â”‚   â”‚   â”œâ”€â”€ trainer.py                  # Base trainer implementation
â”‚   â”‚   â””â”€â”€ utils.py                    # Training utility functions
â”‚   â”‚
â”‚   â”œâ”€â”€ tests/                          # Test scripts
â”‚   â”‚   â””â”€â”€ test_mock_environment.py    # Tests for the mock environment
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                          # Utility functions and monitoring
â”‚   â”‚   â”œâ”€â”€ hardware_monitor.py         # System resource monitoring
â”‚   â”‚   â”œâ”€â”€ image_utils.py              # Image processing utilities
â”‚   â”‚   â”œâ”€â”€ path_utils.py               # Path management for consistent file locations
â”‚   â”‚   â”œâ”€â”€ performance_safeguards.py   # Ensures stable performance
â”‚   â”‚   â””â”€â”€ visualization.py            # Data visualization tools
â”‚   â”‚
â”‚   â”œâ”€â”€ __init__.py                     # Package initialization
â”‚   â””â”€â”€ train.py                        # Main training entry point
â”‚
â”œâ”€â”€ docs/                               # Documentation
â”‚   â”œâ”€â”€ agent.md                        # Agent documentation
â”‚   â”œâ”€â”€ architecture.md                 # System architecture overview
â”‚   â”œâ”€â”€ environment.md                  # Environment documentation
â”‚   â”œâ”€â”€ improvements.md                 # Future improvements
â”‚   â”œâ”€â”€ model.md                        # Model documentation
â”‚   â”œâ”€â”€ README.md                       # Documentation overview
â”‚   â””â”€â”€ training.md                     # Training process documentation
â”‚
â”œâ”€â”€ scripts/                            # Utility scripts
â”‚   â”œâ”€â”€ benchmark.py                    # Performance benchmarking
â”‚   â”œâ”€â”€ dashboard.py                    # Real-time monitoring dashboard
â”‚   â”œâ”€â”€ hyperparameter_tuning.py        # Hyperparameter optimization
â”‚   â”œâ”€â”€ run_environment.py              # Run the environment standalone
â”‚   â”œâ”€â”€ run_mock_training.py            # Training with mock environment
â”‚   â””â”€â”€ visualize_training.py           # Training visualization tools
â”‚
â”œâ”€â”€ .github/                            # GitHub configuration
â”œâ”€â”€ .gitignore                          # Git ignore rules
â”œâ”€â”€ CONTRIBUTING.md                     # Contribution guidelines
â”œâ”€â”€ LICENSE                             # Project license
â”œâ”€â”€ README.md                           # Main README (this file)
â””â”€â”€ requirements.txt                    # Python dependencies
```

**Note**: The following directories are created at runtime:
- `logs/`: Generated log files and tensorboard data
- `output/`: Generated outputs, visualizations, and benchmark results
- `checkpoints/`: Model checkpoints during and after training

These directories are automatically created in the project root when needed by the application. All paths are managed by the path utilities in `src/utils/path_utils.py`, ensuring consistent file locations regardless of which directory you run the scripts from.

## ðŸš€ Installation

### Prerequisites

- Windows 10/11
- NVIDIA GPU (RTX 3080 Ti recommended)
- Cities: Skylines 2
- Python 3.10+

### Setup

1. Clone the repository:
```bash
git clone https://github.com/sfatkhutdinov/cities-skylines-2.git
cd cities-skylines-2-agent
```

2. Create a virtual environment:
```bash
python -m venv venv
```

3. Activate the virtual environment:
```bash
# On Windows
venv\Scripts\activate
# On Linux/Mac
source venv/bin/activate
```

4. Install dependencies:
```bash
pip install -r requirements.txt
```

## ðŸŽ® Usage

### Training

To start training the agent:

```bash
python src/train.py
```

Common options:
```
--num_episodes=1000     # Number of episodes to train
--max_steps=1000        # Maximum steps per episode
--checkpoint_dir=checkpoints  # Directory to save checkpoints
--render                # Display visualization during training
--mock_env              # Use mock environment for testing
--mixed_precision       # Enable mixed precision training
--hardware_config=path/to/config.json  # Custom hardware configuration
```

### Testing with Mock Environment

The project includes a mock environment for testing without requiring the actual game:

```bash
python src/tests/test_mock_environment.py
```

This will run a series of tests on the mock environment, including:
- Basic functionality tests
- Complete episode simulation
- Error condition handling (crashes, freezes, menus)
- Visualization generation

The mock environment simulates:
- City building mechanics
- Population and budget dynamics
- Game crashes and freezes
- Menu interactions
- Reward computation

### Benchmarking

Run comprehensive benchmarks on the agent and environment:

```bash
python src/benchmarks/benchmark_agent.py --episodes=10 --steps=500 --output=benchmark_results
```

Common options:
```
--episodes=10           # Number of episodes to run
--steps=500             # Maximum steps per episode
--config=path/to/config.json  # Configuration file
--output=benchmark_results  # Output directory name
--gpu                   # Force GPU usage
--cpu                   # Force CPU usage
--mixed_precision       # Use mixed precision
```

The benchmark will generate:
- Performance metrics (rewards, episode lengths, success rates)
- Hardware utilization statistics (CPU, GPU, memory)
- Visualizations of agent performance
- Detailed JSON and text reports

### Utility Scripts

The project includes several utility scripts to help with development, analysis, and monitoring:

#### Hyperparameter Tuning

Optimize agent hyperparameters:

```bash
python scripts/hyperparameter_tuning.py --method=random --trials=10 --visualize
```

Common options:
```
--output=hyperparameter_results  # Output directory for results
--method=[grid|random]  # Search method (grid or random search)
--trials=10             # Number of trials for random search
--mock                  # Use mock environment
--epochs=5              # Training epochs per trial
--episodes=5            # Episodes per epoch
--parallel=4            # Number of parallel trials to run
--visualize             # Generate visualizations of results
```

#### Dashboard

Run a real-time dashboard to monitor agent performance:

```bash
streamlit run scripts/dashboard.py -- --log_dir=logs
```

Common options:
```
--log_dir=logs          # Directory containing training logs
--port=8501             # Port to run the dashboard on
--host=localhost        # Host to run the dashboard on
--refresh_interval=30   # Dashboard refresh interval in seconds
```

## ðŸ“‹ Documentation

See the [docs](docs/) directory for detailed documentation on each component.

## ðŸ§ª Testing

Run the tests with:

```bash
python -m unittest discover tests
```

## ðŸ“Š Performance Optimization Features

The agent includes several performance optimization features:

- **Adaptive Resource Management**: Automatically adjusts resource usage based on system capabilities
- **Mixed Precision Training**: Reduces memory usage and increases training speed on compatible GPUs
- **Error Recovery**: Handles game crashes and freezes gracefully to continue training
- **Hardware Monitoring**: Tracks system resource usage to identify bottlenecks
- **Performance Benchmarking**: Tools to measure and optimize agent performance

## ðŸ“ˆ Monitoring

Training progress is logged to the `logs` directory. You can also use Weights & Biases for more detailed monitoring:

```bash
python src/train.py --use_wandb
```

## ðŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details. 